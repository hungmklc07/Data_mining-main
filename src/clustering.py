"""
Module th·ª±c hi·ªán Clustering (K-Means v√† Hierarchical)
"""
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, davies_bouldin_score
import warnings
warnings.filterwarnings('ignore')

def select_features_for_clustering(df, feature_keywords=None, exclude_cols=None):
    """
    Ch·ªçn c√°c features ph√π h·ª£p cho clustering
    
    Parameters:
    -----------
    df : DataFrame
        D·ªØ li·ªáu g·ªëc
    feature_keywords : list
        Danh s√°ch keywords ƒë·ªÉ t√¨m features (m·∫∑c ƒë·ªãnh: c√°c ch·ªâ s·ªë quan tr·ªçng)
    exclude_cols : list
        Danh s√°ch c·ªôt c·∫ßn lo·∫°i b·ªè
    
    Returns:
    --------
    List of feature columns
    """
    if exclude_cols is None:
        exclude_cols = ['Player', 'Nation', 'Pos', 'Squad', 'Born', 'Team', 'Age']
    
    if feature_keywords is None:
        feature_keywords = ['gls', 'ast', 'xg', 'xa', 'sh', 'sot', 'pass', 'tkl', 'touches', 
                           'prg', 'sca', 'gca', 'int', 'blocks', 'carries']
    
    # L·∫•y c√°c c·ªôt s·ªë
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # L·ªçc c√°c c·ªôt c√≥ ch·ª©a keywords
    selected_cols = []
    for col in numeric_cols:
        if col not in exclude_cols:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in feature_keywords):
                # Lo·∫°i b·ªè c√°c c·ªôt c√≥ '%' ho·∫∑c 'category' (ƒë√£ ƒë∆∞·ª£c discretize)
                if '%' not in col and 'category' not in col_lower:
                    selected_cols.append(col)
    
    return selected_cols

def find_optimal_clusters(X, max_k=10, method='kmeans'):
    """
    T√¨m s·ªë c·ª•m t·ªëi ∆∞u s·ª≠ d·ª•ng Elbow Method v√† Silhouette Score
    
    Parameters:
    -----------
    X : array-like
        D·ªØ li·ªáu ƒë√£ scale
    max_k : int
        S·ªë c·ª•m t·ªëi ƒëa ƒë·ªÉ th·ª≠
    method : str
        'kmeans' ho·∫∑c 'hierarchical'
    
    Returns:
    --------
    dict v·ªõi k·∫øt qu·∫£
    """
    inertias = []
    silhouette_scores = []
    davies_bouldin_scores = []
    k_range = range(2, max_k + 1)
    
    for k in k_range:
        if method == 'kmeans':
            model = KMeans(n_clusters=k, random_state=42, n_init=10)
        else:
            model = AgglomerativeClustering(n_clusters=k)
        
        labels = model.fit_predict(X)
        
        if method == 'kmeans':
            inertias.append(model.inertia_)
        
        silhouette_scores.append(silhouette_score(X, labels))
        davies_bouldin_scores.append(davies_bouldin_score(X, labels))
    
    # T√¨m k t·ªëi ∆∞u d·ª±a tr√™n silhouette score (cao nh·∫•t)
    optimal_k = k_range[np.argmax(silhouette_scores)]
    
    results = {
        'k_range': list(k_range),
        'inertias': inertias if method == 'kmeans' else None,
        'silhouette_scores': silhouette_scores,
        'davies_bouldin_scores': davies_bouldin_scores,
        'optimal_k': optimal_k
    }
    
    return results

def perform_kmeans_clustering(X, n_clusters=None, find_optimal=True, max_k=10):
    """
    Th·ª±c hi·ªán K-Means clustering
    
    Parameters:
    -----------
    X : array-like
        D·ªØ li·ªáu ƒë√£ scale
    n_clusters : int
        S·ªë c·ª•m (n·∫øu None s·∫Ω t·ª± t√¨m)
    find_optimal : bool
        C√≥ t√¨m s·ªë c·ª•m t·ªëi ∆∞u kh√¥ng
    max_k : int
        S·ªë c·ª•m t·ªëi ƒëa khi t√¨m optimal
    
    Returns:
    --------
    dict v·ªõi k·∫øt qu·∫£
    """
    if find_optimal or n_clusters is None:
        print("üîç ƒêang t√¨m s·ªë c·ª•m t·ªëi ∆∞u...")
        optimal_results = find_optimal_clusters(X, max_k=max_k, method='kmeans')
        n_clusters = optimal_results['optimal_k']
        print(f"‚úÖ S·ªë c·ª•m t·ªëi ∆∞u: {n_clusters} (Silhouette Score: {optimal_results['silhouette_scores'][n_clusters-2]:.3f})")
    else:
        optimal_results = None
    
    # Th·ª±c hi·ªán clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X)
    
    # T√≠nh c√°c metrics
    silhouette = silhouette_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)
    
    results = {
        'model': kmeans,
        'labels': labels,
        'n_clusters': n_clusters,
        'silhouette_score': silhouette,
        'davies_bouldin_score': davies_bouldin,
        'optimal_results': optimal_results,
        'centers': kmeans.cluster_centers_
    }
    
    return results

def perform_hierarchical_clustering(X, n_clusters=None, find_optimal=True, max_k=10, linkage='ward'):
    """
    Th·ª±c hi·ªán Hierarchical Clustering
    
    Parameters:
    -----------
    X : array-like
        D·ªØ li·ªáu ƒë√£ scale
    n_clusters : int
        S·ªë c·ª•m
    find_optimal : bool
        C√≥ t√¨m s·ªë c·ª•m t·ªëi ∆∞u kh√¥ng
    max_k : int
        S·ªë c·ª•m t·ªëi ƒëa
    linkage : str
        Linkage method ('ward', 'complete', 'average')
    
    Returns:
    --------
    dict v·ªõi k·∫øt qu·∫£
    """
    if find_optimal or n_clusters is None:
        print("üîç ƒêang t√¨m s·ªë c·ª•m t·ªëi ∆∞u...")
        optimal_results = find_optimal_clusters(X, max_k=max_k, method='hierarchical')
        n_clusters = optimal_results['optimal_k']
        print(f"‚úÖ S·ªë c·ª•m t·ªëi ∆∞u: {n_clusters} (Silhouette Score: {optimal_results['silhouette_scores'][n_clusters-2]:.3f})")
    else:
        optimal_results = None
    
    # Th·ª±c hi·ªán clustering
    hierarchical = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)
    labels = hierarchical.fit_predict(X)
    
    # T√≠nh metrics
    silhouette = silhouette_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)
    
    results = {
        'model': hierarchical,
        'labels': labels,
        'n_clusters': n_clusters,
        'silhouette_score': silhouette,
        'davies_bouldin_score': davies_bouldin,
        'optimal_results': optimal_results
    }
    
    return results

def analyze_clusters(df, labels, feature_cols):
    """
    Ph√¢n t√≠ch ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng c·ª•m
    
    Parameters:
    -----------
    df : DataFrame
        D·ªØ li·ªáu g·ªëc
    labels : array
        Cluster labels
    feature_cols : list
        Danh s√°ch features ƒë√£ s·ª≠ d·ª•ng
    
    Returns:
    --------
    DataFrame v·ªõi th·ªëng k√™ t·ª´ng c·ª•m
    """
    df_clustered = df.copy()
    df_clustered['Cluster'] = labels
    
    # T√≠nh th·ªëng k√™ cho t·ª´ng c·ª•m
    cluster_stats = df_clustered.groupby('Cluster')[feature_cols].mean()
    
    # Th√™m s·ªë l∆∞·ª£ng c·∫ßu th·ªß trong m·ªói c·ª•m
    cluster_counts = df_clustered['Cluster'].value_counts().sort_index()
    cluster_stats['Count'] = cluster_counts.values
    
    return cluster_stats

def reduce_dimensions_for_visualization(X, n_components=2):
    """
    Gi·∫£m chi·ªÅu d·ªØ li·ªáu b·∫±ng PCA ƒë·ªÉ visualize
    
    Parameters:
    -----------
    X : array-like
        D·ªØ li·ªáu
    n_components : int
        S·ªë chi·ªÅu sau khi gi·∫£m
    
    Returns:
    --------
    X_reduced : array
        D·ªØ li·ªáu ƒë√£ gi·∫£m chi·ªÅu
    pca : PCA object
    """
    pca = PCA(n_components=n_components, random_state=42)
    X_reduced = pca.fit_transform(X)
    
    return X_reduced, pca


