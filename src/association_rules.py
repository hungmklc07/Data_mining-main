"""
Module th·ª±c hi·ªán Association Rule Mining s·ª≠ d·ª•ng FP-Growth
"""
import pandas as pd
import numpy as np
from mlxtend.frequent_patterns import fpgrowth, association_rules
from mlxtend.preprocessing import TransactionEncoder
import warnings
warnings.filterwarnings('ignore')

def discretize_continuous_features(df, feature_cols, n_bins=3, labels=None):
    """
    Chuy·ªÉn ƒë·ªïi c√°c bi·∫øn li√™n t·ª•c th√†nh c√°c itemset r·ªùi r·∫°c
    
    Parameters:
    -----------
    df : DataFrame
        D·ªØ li·ªáu g·ªëc
    feature_cols : list
        Danh s√°ch c√°c c·ªôt c·∫ßn discretize
    n_bins : int
        S·ªë l∆∞·ª£ng bins (m·∫∑c ƒë·ªãnh 3: Low, Medium, High)
    labels : list
        T√™n labels cho c√°c bins (m·∫∑c ƒë·ªãnh: ['Low', 'Medium', 'High'])
    
    Returns:
    --------
    DataFrame v·ªõi c√°c c·ªôt ƒë√£ ƒë∆∞·ª£c discretize
    """
    df_discrete = df.copy()
    
    if labels is None:
        labels = ['Low', 'Medium', 'High']
    
    for col in feature_cols:
        if col in df_discrete.columns:
            # B·ªè qua c√°c gi√° tr·ªã NaN ho·∫∑c 0
            non_zero = df_discrete[col].replace([np.inf, -np.inf], np.nan).dropna()
            
            if len(non_zero) > 0:
                # T√≠nh quantiles
                q1 = non_zero.quantile(0.33)
                q2 = non_zero.quantile(0.67)
                
                # Discretize
                conditions = [
                    df_discrete[col] <= q1,
                    (df_discrete[col] > q1) & (df_discrete[col] <= q2),
                    df_discrete[col] > q2
                ]
                df_discrete[col + '_category'] = np.select(conditions, labels, default='Low')
            else:
                df_discrete[col + '_category'] = 'Low'
    
    return df_discrete

def create_transaction_dataset(df, feature_cols):
    """
    T·∫°o transaction dataset t·ª´ DataFrame ƒë√£ discretize
    
    Parameters:
    -----------
    df : DataFrame
        DataFrame ƒë√£ discretize
    feature_cols : list
        Danh s√°ch c√°c c·ªôt category c·∫ßn s·ª≠ d·ª•ng
    
    Returns:
    --------
    List of transactions
    """
    transactions = []
    
    for idx, row in df.iterrows():
        transaction = []
        for col in feature_cols:
            if col in df.columns:
                value = str(row[col])
                if pd.notna(value) and value != 'nan' and value != '':
                    # T·∫°o item d·∫°ng "FeatureName=Value"
                    item = f"{col}={value}"
                    transaction.append(item)
        if len(transaction) > 0:
            transactions.append(transaction)
    
    return transactions

def apply_fpgrowth(transactions, min_support=0.1):
    """
    √Åp d·ª•ng FP-Growth ƒë·ªÉ t√¨m frequent itemsets
    
    Parameters:
    -----------
    transactions : list
        List of transactions
    min_support : float
        Minimum support threshold (0-1)
    
    Returns:
    --------
    DataFrame v·ªõi frequent itemsets
    """
    # Chuy·ªÉn ƒë·ªïi transactions th√†nh format ph√π h·ª£p v·ªõi mlxtend
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    df_transactions = pd.DataFrame(te_ary, columns=te.columns_)
    
    # √Åp d·ª•ng FP-Growth
    frequent_itemsets = fpgrowth(df_transactions, min_support=min_support, use_colnames=True)
    
    return frequent_itemsets, df_transactions

def generate_rules(frequent_itemsets, metric="confidence", min_threshold=0.6):
    """
    T·∫°o association rules t·ª´ frequent itemsets
    
    Parameters:
    -----------
    frequent_itemsets : DataFrame
        Frequent itemsets t·ª´ FP-Growth
    metric : str
        Metric ƒë·ªÉ ƒë√°nh gi√° rules (confidence, lift, etc.)
    min_threshold : float
        Minimum threshold cho metric
    
    Returns:
    --------
    DataFrame v·ªõi association rules
    """
    if len(frequent_itemsets) == 0:
        return pd.DataFrame()
    
    rules = association_rules(frequent_itemsets, metric=metric, min_threshold=min_threshold)
    
    # S·∫Øp x·∫øp theo confidence v√† lift
    if len(rules) > 0:
        rules = rules.sort_values(['confidence', 'lift'], ascending=False)
    
    return rules

def analyze_player_performance_patterns(df, min_support=0.15, min_confidence=0.6):
    """
    Ph√¢n t√≠ch m·∫´u ch·ªâ s·ªë c·∫ßu th·ªß d·∫´n ƒë·∫øn hi·ªáu su·∫•t cao
    
    Parameters:
    -----------
    df : DataFrame
        D·ªØ li·ªáu c·∫ßu th·ªß
    min_support : float
        Minimum support
    min_confidence : float
        Minimum confidence
    
    Returns:
    --------
    Tuple: (frequent_itemsets, rules, discretized_df)
    """
    # Ch·ªçn c√°c features quan tr·ªçng
    feature_cols = []
    
    # T√¨m c√°c c·ªôt li√™n quan ƒë·∫øn goals, assists, xG, xA
    goal_cols = [c for c in df.columns if any(kw in c.lower() for kw in ['gls', 'goals']) and 'category' not in c.lower()]
    assist_cols = [c for c in df.columns if any(kw in c.lower() for kw in ['ast', 'assist']) and 'category' not in c.lower()]
    xg_cols = [c for c in df.columns if 'xg' in c.lower() and 'category' not in c.lower() and 'per' not in c.lower()]
    xa_cols = [c for c in df.columns if 'xa' in c.lower() and 'category' not in c.lower() and 'per' not in c.lower()]
    sot_cols = [c for c in df.columns if 'sot' in c.lower() and '%' in c.lower() and 'category' not in c.lower()]
    
    # Ch·ªçn c·ªôt ƒë·∫ßu ti√™n t√¨m ƒë∆∞·ª£c cho m·ªói lo·∫°i
    if goal_cols:
        feature_cols.append(goal_cols[0])
    if assist_cols:
        feature_cols.append(assist_cols[0])
    if xg_cols:
        feature_cols.append(xg_cols[0])
    if xa_cols:
        feature_cols.append(xa_cols[0])
    if sot_cols:
        feature_cols.append(sot_cols[0])
    
    # Th√™m Position n·∫øu c√≥
    if 'Pos' in df.columns:
        feature_cols.append('Pos')
    
    # L·ªçc c√°c c·ªôt c√≥ trong DataFrame
    feature_cols = [c for c in feature_cols if c in df.columns]
    
    if len(feature_cols) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√°c c·ªôt ph√π h·ª£p ƒë·ªÉ ph√¢n t√≠ch")
        return None, None, None
    
    print(f"üìä ƒêang ph√¢n t√≠ch v·ªõi {len(feature_cols)} features: {feature_cols[:5]}...")
    
    # Discretize
    numeric_cols = [c for c in feature_cols if c != 'Pos']
    df_discrete = discretize_continuous_features(df, numeric_cols, n_bins=3)
    
    # T·∫°o category columns list
    category_cols = [c + '_category' for c in numeric_cols]
    if 'Pos' in feature_cols:
        category_cols.append('Pos')
    
    # T·∫°o transactions
    transactions = create_transaction_dataset(df_discrete, category_cols)
    
    if len(transactions) == 0:
        print("‚ö†Ô∏è Kh√¥ng t·∫°o ƒë∆∞·ª£c transactions")
        return None, None, None
    
    # √Åp d·ª•ng FP-Growth
    frequent_itemsets, df_transactions = apply_fpgrowth(transactions, min_support=min_support)
    
    if len(frequent_itemsets) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y frequent itemsets v·ªõi min_support n√†y. H√£y th·ª≠ gi·∫£m min_support.")
        return None, None, None
    
    # Generate rules
    rules = generate_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    
    return frequent_itemsets, rules, df_discrete

def analyze_team_patterns(teams_df, min_support=0.3, min_confidence=0.7):
    """
    Ph√¢n t√≠ch m·∫´u t·∫•n c√¥ng/ph√≤ng th·ªß c·ªßa ƒë·ªôi b√≥ng
    
    Parameters:
    -----------
    teams_df : DataFrame
        D·ªØ li·ªáu ƒë·ªôi b√≥ng
    min_support : float
        Minimum support
    min_confidence : float
        Minimum confidence
    
    Returns:
    --------
    Tuple: (frequent_itemsets, rules, discretized_df)
    """
    # Ch·ªçn c√°c features quan tr·ªçng
    feature_cols = []
    
    # T√¨m c√°c c·ªôt li√™n quan
    gf_cols = [c for c in teams_df.columns if 'gf' in c.lower() and 'category' not in c.lower()]
    ga_cols = [c for c in teams_df.columns if 'ga' in c.lower() and 'category' not in c.lower()]
    xg_cols = [c for c in teams_df.columns if 'xg' in c.lower() and 'xga' not in c.lower() and 'category' not in c.lower()]
    xga_cols = [c for c in teams_df.columns if 'xga' in c.lower() and 'category' not in c.lower()]
    pts_cols = [c for c in teams_df.columns if 'pts' in c.lower() and 'category' not in c.lower()]
    
    # Ch·ªçn c·ªôt ƒë·∫ßu ti√™n t√¨m ƒë∆∞·ª£c
    for col_list in [gf_cols, ga_cols, xg_cols, xga_cols, pts_cols]:
        if col_list:
            feature_cols.append(col_list[0])
    
    feature_cols = [c for c in feature_cols if c in teams_df.columns]
    
    if len(feature_cols) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√°c c·ªôt ph√π h·ª£p")
        return None, None, None
    
    print(f"üìä ƒêang ph√¢n t√≠ch ƒë·ªôi b√≥ng v·ªõi {len(feature_cols)} features...")
    
    # Discretize
    df_discrete = discretize_continuous_features(teams_df, feature_cols, n_bins=3)
    
    # T·∫°o category columns
    category_cols = [c + '_category' for c in feature_cols]
    
    # T·∫°o transactions
    transactions = create_transaction_dataset(df_discrete, category_cols)
    
    if len(transactions) == 0:
        return None, None, None
    
    # √Åp d·ª•ng FP-Growth
    frequent_itemsets, df_transactions = apply_fpgrowth(transactions, min_support=min_support)
    
    if len(frequent_itemsets) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y frequent itemsets. H√£y th·ª≠ gi·∫£m min_support.")
        return None, None, None
    
    # Generate rules
    rules = generate_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    
    return frequent_itemsets, rules, df_discrete


